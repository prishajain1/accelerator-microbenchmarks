benchmarks:
# - benchmark_name: ppermute
#   benchmark_sweep_params:
#   - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 256}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: all_gather
#   benchmark_sweep_params:
#   - {matrix_dim_range: {start: 1024, end: 4096, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 256}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: psum
#   benchmark_sweep_params:
#   - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 256}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: psum_scatter
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 256, end: 29696, increase_by: 256}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 256, num_runs: 100}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: all_to_all
#   benchmark_sweep_params:
#   - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 256}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "naive_matmul"
#   benchmark_sweep_params:
#   - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "single_host_naive_matmul"
#   benchmark_sweep_params:
#   - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "multilayer_collective_matmul"
#   benchmark_sweep_params:
#   - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "collective_matmul_one_direction"
#   benchmark_sweep_params:
#   - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "naive_attention"
#   benchmark_sweep_params:
#   - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: false}
#   - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true, scale: false}
#   - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true, scale: false}
#   - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true, scale: false}
#   - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false, scale: false}
#   - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: true}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "pallas_flash_attention"
#   benchmark_sweep_params:
#   - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
#   - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
#   - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
#   - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
#   - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "splash_attention"
#   benchmark_sweep_params:
#   - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
#   - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
#   - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
#   - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
#   - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "flax_nnx_attention"
#   benchmark_sweep_params:
#   - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
#   - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
#   - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
#   - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "flax_linen_attention"
#   benchmark_sweep_params:
#   - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
#   - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
#   - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
#   - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
# - benchmark_name: "keras_attention"
#   benchmark_sweep_params:
#   - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
#   - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
#   - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
#   - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
#   xlml_metrics_dir: "/tmp/microbenchmarks/outputs"

